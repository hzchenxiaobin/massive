### 2.3 一个向量加法的kernel

我们使用向量加法来演示CUDA C程序结构。向量加法可以说是最简单的数据并行计算，相当于顺序编程中的“Hello World”。在展示向量加法的内核代码之前，首先回顾一下传统向量加法（主机代码）函数的工作方式是有帮助的。代码2.4展示了一个由主函数和向量加法函数组成的简单传统C程序。在所有示例中，每当需要区分主机和设备数据时，我们会在host使用的变量名后加上“\_h”，在device使用的变量名后加上“\_d”，以提醒我们这些变量的预期用途。由于图2.4中只有主机代码，所以我们只看到以“_h”结尾的变量。

```C
// Compute vector sum C_h = A_h + B_h
void vecAdd(float* A_h, float* B_h, float* C_h, int n) {
  for (int i = 0; i < n; ++i) {
    C_h[i] = A_h[i] + B_h[i];
  }
}
int main() {
	// Memory allocation for arrays A, B, and C
	// I/O to read A and B, N elements each
	...
	vecAdd(A, B, C, N);
}
```

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        代码2.4
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            一个简单的传统向量加法C代码示例。
        </p>
    </figcaption>
</figure>

> #### C语言中的指针
>
> 代码2.4中的函数参数A、B和C是指针。在C语言中，指针可用于访问变量和数据结构。虽然可以用如下语句申明浮点变量V:
>
> ```c
> float V
> ```
>
> 可以声明一个指针变量P:
>
> ```c
> float *P
> ```
>
> 通过语句`P = &V;`将V的地址赋值给P，我们使P“指向”V。*P成为V的同义词。例如，`U = *P;`将V的值赋给U。另一个例子，`*P = 3;`将V的值改为3。
>
> 在C程序中，可以通过指向数组第0个元素的指针来访问数组。例如，语句`P = &(A[0]);`使P指向数组A的第0个元素。这样，P[i]就成为A[i]的同义词。事实上，数组名A本身就是指向其第0个元素的指针。
>
> 在代码2.4中，将数组名A作为传递给函数vecAdd的第一个参数，使得函数的第一个参数A_h指向数组A的第0个元素。因此，在函数体内，可以使用A_h[i]来访问主函数中数组A的A[i]元素。
>
> 请参阅Patt & Patel (2020)的著作，其中详细解释了C语言中指针的用法，内容易于理解。

假设要添加的向量存储在主程序中分配和初始化的数组A和B中。输出向量存储在主程序中同样分配的数组C中。为简洁起见，我们不显示主函数中如何分配或初始化A、B和C的细节。这些数组的指针与包含向量长度的变量N一起传递给vecAdd函数。请注意，vecAdd函数的参数后缀为“_h”，以强调它们由host使用。在接下来的几步中引入设备代码时，这种命名惯例将会很有帮助。

在代码2.4中，vecAdd函数使用for循环迭代访问向量元素。在第i次迭代中，输出元素C_h[i]接收A_h[i]和B_h[i]的和。向量长度参数n用于控制循环，使得迭代次数与向量的长度相匹配。函数通过指针A_h、B_h和C_h分别读取A和B的元素，并将结果写入C的元素。当vecAdd函数返回时，主函数中的后续语句可以访问C的新内容。

<img id="fig1.1" src="..\pic\chapter2\fig2.5.jpeg">

```c
void vecAdd(float* A, float* B, float* C, int n) {
	int  size = n* sizeof(float);
	float  *d_A *d_B, *d_C;
	
	// Part 1: Allocate device memory for A, B, and C
	// Copy A and B to device memory
	...

	// Part 2: Call kernel – to launch a grid of threads
	// to perform the actual vector addition
	...

	// Part 3: Copy C from the device memory
	// Free device vectors
	...
}
```

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        代码2.5
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            将vecAdd函数转移到device的代码大纲。
        </p>
    </figcaption>
</figure>
直接在并行环境中执行向量加法的一种简单方法是修改vecAdd函数，并将其计算移动到device上。修改后的vecAdd函数的结构如代码2.5所示。函数的第一部分在device（GPU）内存中分配空间来存储A、B和C向量的副本，并将A和B向量从主机内存复制到设备内存。第二部分调用实际的向量加法内核来在设备上启动一个grid的线程。第三部分将和向量C从设备内存复制到主机内存，并释放设备内存中的这三个数组。

请注意，修订后的vecAdd函数本质上是一个外包代理，将输入数据发送到设备，启动设备上的计算，并从设备收集结果。这个代理的这种执行方式使得主程序甚至无需知晓向量加法实际上是在device上执行的。实际上，这种“透明”的外包模型可能非常低效，因为需要频繁地复制数据。通常情况下，会将大型和重要的数据结构保留在device上，并从host代码中调用device的函数。然而，目前我们将使用简化的透明模型来介绍基本的CUDA C程序结构。修订后函数的详细信息以及如何编写内核函数将是本章的余下部分的主题。
