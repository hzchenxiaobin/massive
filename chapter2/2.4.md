### 2.4 global memory和数据传输

在当前的CUDA系统中，device通常是带有其自身动态随机存取内存（device global memory）的硬件卡。例如，NVIDIA Volta V100 配备有16GB或32GB的全局内存。将其称为“全局”内存是为了将其与其他类型的device内存区分开来，这些内存可以被程序员访问。有关CUDA内存模型和不同类型device内存的详细信息将在第五章《内存架构和数据局部性》中讨论。

对于向量加法内核，在调用内核之前，程序员需要在global memory中分配空间，并将数据从host内存传输到global memory中的分配空间。这对应于代码2.5的第1部分。同样地，在device执行之后，程序员需要将结果数据从global memory传输回host内存，并释放global memory中不再需要的分配空间。这对应于代码2.5的第3部分。CUDA运行时系统（通常在host上运行）提供API来代表程序员执行这些活动。我们将简单地说数据从host传输到device，作为将数据从host内存复制到global memory的简写。同样适用于相反的方向。

在代码2.5中，vecAdd函数的第1部分和第3部分需要使用CUDA API函数来分配global memory用于存储A、B和C；将A和B从host传输到device；在向量加法完成后将C从device传输回host；并释放global memory上的A、B和C。我们将首先解释内存分配和释放函数。

> ##### CUDA管理global memory的API
>
> **cudaMalloc()**
>
> - 在global memory中分配对象
> - 两个参数：
>   - 指向分配对象的指针
>   - 以byte为单位的分配对象的大小
>
> **cudaFree()**
>
> - 释放在global memory上的对象
>   - 被释放对象的指针

cudaMalloc 函数可以从host代码中调用，用于为对象分配一块global memory。读者应该注意到 cudaMalloc 和标准 C 运行时库 malloc 函数之间的显著相似性。这是有意为之的；CUDA C 是带有少量扩展的 C。CUDA C 使用标准 C 运行时库的 malloc 函数来管理host内存，【注脚2】并添加了 cudaMalloc 作为 C 运行时库的扩展。通过尽可能地保持接口与原始 C 运行时库的相似性，CUDA C 最大限度地减少了 C 程序员重新学习这些扩展的时间。

cudaMalloc 函数的第一个参数是一个指针变量的地址，该变量将被设置为指向分配的对象。指针变量的地址应被强制转换为 (void **)，因为该函数接收为一个通用指针；内存分配函数是一个通用函数，不局限于任何特定类型的对象。【注脚3】这个参数允许 cudaMalloc 函数将分配的内存地址写入提供的指针变量中，而不管其类型如何。【注脚4】调用kernel的host代码将这个指针值传递给需要访问所分配内存对象的kernel 代码。cudaMalloc 函数的第二个参数是要分配的数据大小，以字节数表示。这个第二个参数的用法与 C 语言中 malloc 函数的 size 参数一致。

我们现在使用以下简单的代码示例来说明 cudaMalloc 和 cudaFree 的使用：

```c
float *A_d
int size=n sizeof(float);
cudaMalloc((void **)&A_d, size);
...
cudaFree(A_d);
```

*【注脚2】CUDA C 还有更高级的库函数用于在host内存中分配空间。我们将在第20章《编程异构计算集群》中讨论它们。*

*【注脚3】cudaMalloc 返回一个通用对象的使得使用动态分配的多维数组更加复杂。我们将在第 3.2 节中讨论这个问题。*

*【注脚4】请注意，cudaMalloc 的格式与 C 语言的 malloc 函数不同。C 语言的 malloc 函数返回一个指向分配对象的指针。它只接受一个指定分配对象大小的参数。而 cudaMalloc 函数会写入作为第一个参数提供的指针变量。因此，cudaMalloc 函数需要两个参数。cudaMalloc 的双参数格式使其能够使用返回值来报告错误，这与其他 CUDA API 函数的方式相同。*

这是代码2.5中的示例的延续。为清楚起见，我们在指针变量后缀添加“_d”，以表示它指向global memory中的对象。传递给 cudaMalloc 的第一个参数是指针 A_d 的地址（即 &A_d），并将其强制转换为 void 指针。当 cudaMalloc 返回时，A_d 将指向为向量 A 分配的global memory区域。传递给 cudaMalloc 的第二个参数是要分配的区域大小。由于大小以字节数表示，程序员需要在确定大小值时将数组中的元素数量转换为字节数。例如，在为包含 n 个单精度浮点元素的数组分配空间时，大小的值将是 n 乘以单精度浮点数的大小，即今天计算机中的4个字节。因此，大小的值将是 n * 4。在计算完成后，通过将指针 A_d 作为参数调用 cudaFree 来释放global memory中向量 A 的存储空间。请注意，cudaFree 不需要更改 A_d 的值；它只需要使用 A_d 的值将分配的内存返回到可用池中。因此，作为参数传递的是 A_d 的值而不是地址。

A_d、B_d 和 C_d 中的地址指向global memory中的位置。这些地址不应在主机代码中被解引用。它们应在调用 API 函数和kernel函数时使用。在host代码中解引用global memory指针可能会导致异常或其他类型的运行时错误。

读者应该根据代码2.5中vecAdd示例的第1部分，完成类似B_d 和 C_d 指针变量的声明，并对它们进行相应的 cudaMalloc 调用。此外，代码2.5中的第3部分可以通过对 B_d 和 C_d 调用 cudaFree 来完成。

> ##### host与kernel之间数据传输的CUDA API函数
>
> cudaMemcpy()
>
> - 内存数据传输
> - 4个参数
>   - 指向目标位置的指针
>   - 指向源位置的指针
>   - 拷贝数据的字节数
>   - 传输数据的类型/方向

一旦host代码为数据对象在global memory中分配了空间，就可以请求将数据从host传输到kernel。这可以通过调用CUDA API的函数来完成。cudaMemcpy函数接受四个参数。第一个参数是指向要复制的数据对象的目标位置的指针。第二个参数指向源位置。第三个参数指定要复制的字节数。第四个参数指示涉及复制的内存类型：从host到host，从host到kernel，从kernel到hsot，以及从kernel到kernel。例如，内存复制函数可以用来将数据从global memory中的一个位置复制到另一个位置。

vecAdd 函数在进行向量相加之前调用 cudaMemcpy 函数，将 A_h 和 B_h 向量从host内存复制到kernel内存中的 A_d 和 B_d，并在相加完成后将 C_d 向量从kernel内存复制到host内存中的 C_h。假设 A_h、B_h、A_d、B_d 和 size 的值已经如前所述设置完毕，下面展示了这三个 cudaMemcpy 调用。两个符号常量 cudaMemcpyHostToDevice 和 cudaMemcpyDeviceToHost 是 CUDA 编程环境中预定义的常量。请注意，通过正确排列源和目标指针并使用适当的传输类型常量，可以使用同一函数在两个方向上传输数据。

```c
cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice); 
cudaMemcpy(B_d, B_h, size, cudaMemcpyHostToDevice);
...
cudaMemcpy(C_h, C_d, size, cudaMemcpyDeviceToHost);
```

总而言之，图2.4中的主程序调用了同样在主机上执行的vecAdd函数。图2.5概述的vecAdd函数在设备全局内存中分配空间，请求数据传输，并调用执行实际向量加法的内核。我们将这种类型的主机代码称为调用内核的存根。在图2.8中，我们展示了一个更完整的vecAdd函数版本。





```c
void vecAdd(float* A_h, float* B_h, float* C_h, int n) {
  int size = n * sizeof(float);
  float *A_d, *B_d, *C_d;
  
  cudaMalloc((void **) &A_d, size);
  cudaMalloc((void **) &B_d, size);
  cudaMalloc((void **) &C_d, size);
  
  cudaMemcpy(A_d, A_h, size, cudaMemcpyHostToDevice);
  cudaMemcpy(B_d, B_h, size, cudaMemcpyHostToDevice);
  
  // Kernel invocation code – to be shown later
  ...
  
  cudaMemcpy(C_h, C_d, size, cudaMemcpyDeviceToHost);
  
  cudaFree(A_d);
  cudaFree(B_d);
  cudaFree(C_d);
}
```

