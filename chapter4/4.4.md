### 4.4 Warp和SIMD硬件

我们已经看到，block之间可以以任何顺序执行，这允许在不同设备上实现透明的可伸缩性。然而，我们没有详细讨论每个block内线程的执行时间。从概念上讲，应该假设block内的线程可以相互之间以任何顺序执行。在具有阶段性的算法中，每当我们希望确保所有线程在开始下一阶段之前都已经完成前一阶段的执行时，应使用屏障同步。如果没有使用屏障同步，内核执行的正确性不应依赖于某些线程会彼此同步执行的假设。

CUDA GPU中的线程调度是一个硬件实现概念，因此必须在具体硬件实现的背景下讨论。在目前的大多数实现中，一旦一个block被分配给一个SM（流式多处理器），它将进一步划分为32线程的单元，称为warp。warp的大小是特定于实现的，在未来的GPU代中可能会有所变化。了解warp有助于理解和优化特定代CUDA设备上的CUDA应用程序的性能。

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.6" src="..\pic\chapter4\fig4.6.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.6
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            线程调度中将block划分为warps
        </p>
    </figcaption>
</figure>

一个warp是SM中线程调度的单位。图4.6展示了在某个实现中block被划分为warp的情况。在这个例子中，有三个block——block1、block2和block3——都被分配到一个SM中。每个block进一步划分为warp以便进行调度。每个warp由32个连续的threadIdx值的线程组成：线程0到31形成第一个warp，线程32到63形成第二个warp，依此类推。我们可以根据给定的block大小和分配给每个SM的block数来计算一个SM中包含的warp数量。在这个例子中，如果每个block有256个线程，我们可以确定每个block有256/32，即8个warp。由于SM中有三个block，所以我们有8 * 3 = 24个warp在SM中。

Block根据线程索引划分为warp（线程束）。如果一个block被组织成一维数组，即只使用threadIdx.x，那么划分是很简单的。warp中的threadIdx.x值是连续且递增的。对于32大小的warp，warp 0从线程0开始，到线程31结束；warp 1从线程32开始，到线程63结束，依此类推。一般来说，warp n从线程32n开始，到线程32(n+1)-1结束。对于大小不是32的倍数的block，最后一个warp将填充无效线程以填满32个线程位置。例如，如果一个block有48个线程，它将被划分为两个warp，第二个warp将填充16个无效线程。

对于由多个维度的线程组成的block，在分配到多个warp之前，这些维度会投影到一个线性化的行优先布局中。线性布局的确定方法是将具有较大y和z坐标的行放在具有较小y和z坐标的行之后。也就是说，如果一个block由两个维度的线程组成，那么线性布局的形成方式是将所有threadIdx.y为1的线程放在所有threadIdx.y为0的线程之后。threadIdx.y为2的线程会放在threadIdx.y为1的线程之后，依此类推。具有相同threadIdx.y值的线程会按照threadIdx.x值递增的顺序连续排列。

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.7" src="..\pic\chapter4\fig4.7.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.7
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            将2D的线程映射成线性布局
        </p>
    </figcaption>
</figure>

图4.7展示了将一个二维block的线程放置到线性布局中的示例。上半部分展示了该block的二维视图。读者应认识到其与二维数组的行优先布局的相似性。每个线程表示为T<sub>y,x</sub>，其中x表示threadIdx.x，y表示threadIdx.y。图4.7的下半部分展示了block的线性化视图。前四个线程是threadIdx.y值为0的线程；它们按threadIdx.x值递增的顺序排列。接下来的四个线程是threadIdx.y值为1的线程，它们也按threadIdx.x值递增的顺序排列。在这个例子中，所有16个线程形成了半个warp。warp将会填充另16个线程以完成一个32线程的warp。想象一个有8x8个线程的二维块。这64个线程将形成两个warp。第一个warp从T<sub>0,0</sub>开始，到T<sub>3,7</sub>结束。第二个warp从T<sub>4,0</sub>开始，到T<sub>7,7</sub>结束。读者可以通过绘制图示来进行练习，这会很有帮助。

对于一个三维的block，我们首先将所有threadIdx.z值为0的线程按线性顺序排列。这些线程被视为一个二维的block，如图4.7所示。接下来将所有threadIdx.z值为1的线程按线性顺序排列，依此类推。例如，对于一个三维2×8×4的块（x维度为4，y维度为8，z维度为2），这64个线程将被划分成两个warps，第一个warp包含从T<sub>0,0,0</sub>到T<sub>0,7,3</sub>的线程，第二个warp包含从T<sub>1,0,0</sub>到T<sub>1,7,3</sub>的线程。

一个SM 设计用于按照单指令多数据 (SIMD) 模型执行一个warp中的所有线程。也就是说，在任意时刻，所有线程将获取并执行同一条指令（参见“Warps和SIMD硬件”边栏）。图4.8展示了SM中的core如何分组为处理块，每8个core组成一个处理块并共享一个指令获取/分派单元。以实际例子为例，Ampere A100 SM拥有64个core，被组织为四个处理块，每个处理块有16个core。同一warp中的线程被分配到同一个处理块，该处理块获取指令并同时为warp中的所有线程执行它。这些线程对数据的不同部分应用相同的指令。由于SIMD硬件有效地限制了一个warp中的所有线程在任何时刻执行相同的指令，因此warp的执行行为通常被称为单指令多线程。

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.8" src="..\pic\chapter4\fig4.8.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.8
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            为了SIMD执行方式，SM被组织成处理块
        </p>
    </figcaption>
</figure>







