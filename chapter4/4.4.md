### 4.4 Warp和SIMD硬件

我们已经看到，block之间可以以任何顺序执行，这允许在不同设备上实现透明的可伸缩性。然而，我们没有详细讨论每个block内线程的执行时间。从概念上讲，应该假设block内的线程可以相互之间以任何顺序执行。在具有阶段性的算法中，每当我们希望确保所有线程在开始下一阶段之前都已经完成前一阶段的执行时，应使用屏障同步。如果没有使用屏障同步，内核执行的正确性不应依赖于某些线程会彼此同步执行的假设。

CUDA GPU中的线程调度是一个硬件实现概念，因此必须在具体硬件实现的背景下讨论。在目前的大多数实现中，一旦一个block被分配给一个SM（流式多处理器），它将进一步划分为32线程的单元，称为warp。warp的大小是特定于实现的，在未来的GPU代中可能会有所变化。了解warp有助于理解和优化特定代CUDA设备上的CUDA应用程序的性能。

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.6" src="..\pic\chapter4\fig4.6.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.6
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            线程调度中将block划分为warps
        </p>
    </figcaption>
</figure>

一个warp是SM中线程调度的单位。图4.6展示了在某个实现中block被划分为warp的情况。在这个例子中，有三个block——block1、block2和block3——都被分配到一个SM中。每个block进一步划分为warp以便进行调度。每个warp由32个连续的threadIdx值的线程组成：线程0到31形成第一个warp，线程32到63形成第二个warp，依此类推。我们可以根据给定的block大小和分配给每个SM的block数来计算一个SM中包含的warp数量。在这个例子中，如果每个block有256个线程，我们可以确定每个block有256/32，即8个warp。由于SM中有三个block，所以我们有8 * 3 = 24个warp在SM中。