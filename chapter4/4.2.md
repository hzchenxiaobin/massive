### 4.2 Block调度

当一个kernel函数被调用时，CUDA运行时系统会启动一个grid来执行kernel的代码。这些线程是按block分配给SM的，也就是说，一个block中的所有线程会同时分配给同一个SM。

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.2" src="..\pic\chapter4\fig4.2.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.2
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            block分配到SM
        </p>
    </figcaption>
</figure>
[图 4.2](#fig4.2) 展示了block分配到 SM 的情况。多个block可能会同时分配给同一个 SM。例如，在[图 4.2](#fig4.2) 中，每个 SM 分配了三个block。然而，blockj需要保留硬件资源才能执行，因此一个给定的 SM 上能同时分配的块数是有限的。块数的限制取决于多种因素，这些因素将在第 4.6 节讨论。

由于 SM 的数量有限且每个 SM 能同时分配的block也有限，在 CUDA 设备中能同时执行的block的总数是有限的。大多数grid包含的block远多于这个限制。为了确保grid中的所有block都能执行，运行时系统会维护一个需要执行的block列表，并在先前分配的block完成执行后将新块分配给 SM。

按block分配线程到 SM 保证了同一block中的线程会同时在同一个 SM 上调度。这一保证使得同一block中的线程能够以不同block中的线程无法实现的方式进行交互[^1]。这包括第 4.3 节讨论的屏障同步，还包括访问位于 SM 上的低延迟共享内存，这将在第 5 章“内存架构和数据局部性”中讨论。



[^1]: 不同block中的线程可以通过 Cooperative Groups API 执行屏障同步。然而，必须遵守一些重要的限制，以确保所有参与的线程确实在 SM 上同时执行。感兴趣的读者可以参考 CUDA C 编程指南，了解 Cooperative Groups API 的正确使用方法。
