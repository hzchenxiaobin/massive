### 4.1 现代GPU架构

<figure>
    <style>
     hr {
         border: none;
         height: 2px;
         background-color: black;
         margin: 5px auto;
     }
	</style>
    <img id="fig4.1" src="..\pic\chapter4\fig4.1.jpeg">
    <figcaption>
        <p class="no-indent" style="font-weight: bold;">
        图4.1
        </p>
       	<hr style="border: none; height: 2px; background-color: black; margin: 5px auto;">
        <p class="no-indent" style="font-family: 'Arial', 'Helvetica', sans-serif;color: #808080">
            支持CUDA的GPU架构
        </p>
    </figcaption>
</figure>
图4.1展示了一个典型的面向CUDA C程序员的支持CUDA的GPU的高层次架构视图。它由高度线程化的流式多处理器（SM）数组组成。每个SM有多个处理单元，称为流式处理器或CUDA核心（为了简洁起见，下文简称为核心），如[图4.1](#fig4.1)中SM内的小方块所示，这些核心共享控制逻辑和内存资源。例如，Ampere A100 GPU有108个SM，每个SM有64个核心，总计6912个核心。

SM 还配备了不同的片上内存结构，在[图 4.1](#fig4.1) 中统称为“内存”。这些片上内存结构将是第 5 章“内存架构与数据局部性”的主题。GPU 还配备了几GB的片外设备内存，在[图 4.1](#fig4.1) 中称为“全局内存”。虽然较旧的 GPU 使用图形双倍数据速率同步 DRAM，但从 NVIDIA 的 Pascal 架构开始，更新的 GPU 可能会使用 HBM（高带宽内存）或 HBM2，这些内存包括与 GPU 紧密集成在同一封装中的 DRAM（动态随机存取存储器）模块。为简洁起见，本书将把所有这些类型的内存统称为 DRAM。在第 6 章“性能考虑因素”中，我们将讨论访问 GPU DRAM 所涉及的最重要的概念。