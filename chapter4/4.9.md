### 4.9 总结

GPU 被组织成多个 SM，每个 SM 包含多个处理核心block，这些block共享控制逻辑和内存资源。当一个grid被启动时，block会以任意顺序分配给 SM，从而实现 CUDA 应用程序的透明可扩展性。这种透明的可扩展性带来了一定的限制：不同block中的线程无法相互同步。

线程按block分配给 SM 进行执行。一旦一个block被分配给一个 SM，它会进一步被划分为多个 warps。warp 中的线程按照 SIMD（单指令多数据）模型执行。如果同一个 warp 中的线程由于采取不同的执行路径而发生分歧，处理block会按路径分批次执行这些路径，每个线程只在对应其所采取路径的批次中处于活动状态。

一个 SM 可能会被分配比其能同时执行的更多的线程。在任何时候，SM 只执行其驻留的 warp 中一小部分的指令。这使得其他 warp 可以等待长延迟操作而不会降低大量处理单元的整体执行吞吐量。分配给 SM 的线程数量与其能支持的最大线程数量的比率被称为占用率。SM 的占用率越高，它就越能隐藏长延迟操作。

每个 CUDA 设备对每个 SM 可用资源的数量施加了不同的限制。例如，每个 CUDA 设备对其每个 SM 能容纳的block数、线程数、寄存器数和其他资源的数量都有一个限制。对于每个内核，这些资源限制中的一个或多个可能成为占用率的限制因素。CUDA C 为程序员提供了在运行时查询 GPU 可用资源的功能。